---
title: "ZQM Waterbody Prioritization Models"
author: "Chris Madsen"
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
    df_print: kable
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(psych)
library(readxl)
library(raster)
library(rbin)
library(tidyverse)
library(sf)
library(leaflet)
library(ggsflabel)
library(BAMMtools)
library(RColorBrewer)
library(openxlsx)
library(diffdf)

my_opts = read_csv(paste0(str_extract(getwd(), '.*ZQMussels/'),"Options.csv"))
my.year = my_opts$year

knitr::opts_chunk$set(
	echo = FALSE,
	fig.height = 10,
	fig.width = 10,
	message = FALSE,
	warning = FALSE,
	root.dir = paste0(my_opts$zqm_operations_data_folder,"Watercraft Inspection Data/Multiyear data/")
)

#knitr::opts_knit$set(root.dir = paste0(my_opts$"I:/SPECIES/Zebra_Quagga_Mussel/Operations/Watercraft Inspection Data/Multiyear data/")
```

This R Markdown document estimates the invasion risk of Zebra-Quagga Mussels in freshwater water bodies in British Columbia. 

```{r import_waterbody_data}
waterb = read_sf(paste0(my_opts$remote_spatial_data,"shared_data_sets/waterb_with_data.shp")) %>% 
  dplyr::select(WATERSH,WATERBO,GNIS_NA)

data_to_add = read_excel(paste0(my_opts$zqm_operations_data_folder,"Watercraft Inspection Data/Multiyear data/waterb_with_data_explored.xlsx"))

waterb = waterb %>% 
  left_join(data_to_add)

rm(data_to_add)

bc = read_sf(paste0(my_opts$remote_spatial_data,"shared_data_sets/bc_shapefile.shp"))

bind_cols_fill <- function(df_list) {

  max_rows <- map_int(df_list, nrow) %>% max()
  
  map(df_list, function(df) {
    if(nrow(df) == max_rows) return(df)
    first <- names(df)[1] %>% sym()
    df %>% add_row(!!first := rep(NA, max_rows - nrow(df)))
  }) %>% bind_cols()
}
```

# Assign Risk Estimate to Water Bodies

* Four categories of variables were defined: 
  + 1. Use (Total Watercraft Inspections, Angler use, and number of marinas)
  + 2. High-risk (High-risk Inspections and Transport Canada Operation Restrictions)
  + 3. Mussel-Fouled (Mussel-fouled Inspections)
  + 4. Subwatershed-scale mean dissolved calcium
  
Prior to running the model, each variable was binned separately into three bins as defined by that variable's natural breaks. Because of a small number of outliers with exceptionally high values for many variables, the top 5% of each variable's distribution was temporarily excluded to find these natural breaks. Bin 1 represents the lowest risk estimate and 3 represents the highest risk of invasion. 

Three of the variables were classified differently. Operational restrictions on power/electric propulsion of vessels were assigned a value of -2, and restrictions on power propulsion were assigned a value of -1. Mussel-fouled inspections were  waterbodies with any mussel-fouled inspections were assigned a value of 1 for the variable *M*, while those waterbodies without mussel-fouled inspections received a 0 for *M*. Mean dissolved calcium was binned into three levels prior to inclusion in this analysis: minimal risk (<8 mg/L), moderate (between 8 and 20 mg/L), and high risk (20+ mg/L), but in this analysis the minimal risk subwatersheds (or subwatersheds lacking EMS data) were assigned a value of 0 risk, moderate subwatersheds were assigned a value of 1, and high risk watersheds were assigned a value of 2.

Note that a third category of Operational restrictions is present in the Transport Canada data: complete boating restriction. However, the 49 locations with complete boating restrictions are primarily located in small parts of Okanagan Lake. To avoid these data points flagging Okanagan Lake as completely watercraft-vessel-free (which is untrue), I have removed the 'complete restrictions' from the analysis.

# Risk Model

The following risk model was constructed with _a priori_ knowledge of key variable inputs:

$$R_w = (\frac{T_w+A_w+M_w}{n_w}) + (\frac{H_w-O_w}{n_w}) + (\frac{M_w}{n_w}) + (C_w)$$

Where _Rw_ represents the overall risk estimate of a water body *w*. *T* refers to the total number of watercraft inspections of watercraft headed to waterbody *y*, *A* to angling effort (sum of angling days), *M* to the number of marinas in waterbody *w*, *H* to high-risk motorized inspections and *O* refers to operational restrictions. *M* to mussel-fouled inspections, and *C* stands for the subwatershed-level calcium level (calculated using Environment Monitoring System data). *O* represents a risk reduction, and so it is subtracted from the overall risk estimate.

```{r split_into_motorized_and_non}
waterb = waterb %>% 
  ungroup() %>% 
  mutate(Lowrisk_mot = LwR_C_C + LwR_S_C + LR_V_C_,
         HR_mot = HR_Cm_C + HR_V_C_ + HR_Sm_C) %>% 
  rename(Lowrisk_nonmot = LR_N_M_,
         HR_nonmot = HR_N_M_,
         TtlInsp = TtlInspc) %>% 
  dplyr::select(-TotlInsp)
```

```{r pivot_data_long_and_bin}
#Define variable groupings.
all.my.vars = c("TtlInsp","Marinas","Sum.of.days.fished",
                 "HR_mot","HR_nonmot","NmbrMsF","OperRes")
MusselFouledvar = "NmbrMsF"
Usevars = c("TtlInsp","Sum.of.days.fished","Marinas")
Highriskvars = c("HR_mot","OperRes")

#Establish a layer that has our risk variables of choice in their original format
#as well as the binned values that we find below. We'll add those latter values lower down
#in the script.
waterb_og_values_and_bins = waterb %>%
  dplyr::select(WATERSH,WATERBO,GNIS_NA,all_of(all.my.vars)) %>% 
  dplyr::select(everything(), HR_mot, HR_nonmot) %>% 
  filter(!is.na(TtlInsp) | !is.na(Marinas) | !is.na(Sum.of.days.fished) |
         !is.na(HR_mot) | !is.na(NmbrMsF) | !is.na(OperRes))

all.my.vars = all.my.vars[-5]

#Pivot data (select variables only) long.
data_long = waterb %>%
  st_drop_geometry() %>% 
  #Keep only the variables we've chosen for the 3 groups of variables.
  dplyr::select(WATERSH,WATERBO,GNIS_NA,
         all_of(all.my.vars)) %>% 
  #Change "OperRes" from character to numeric.
  mutate(OperRes = case_when(
    OperRes == "All Vessels Prohibited" ~ "3",
    OperRes == "Power/Electric Prohibited" ~ "1",
    OperRes == "Power Vessels Prohibited" ~ "1",
    TRUE ~ OperRes)) %>% 
  mutate(OperRes = replace(OperRes, OperRes == "3", "NA")) %>% 
  mutate(OperRes = as.numeric(OperRes)) %>% 
  pivot_longer(all_of(all.my.vars), names_to = "varname", values_to = "original.value") %>% 
  filter(!is.na(original.value))

#Write out 
#Remove 0 values/NAs and temporarily remove top 5% to find natural break points.
natural_break_points = data_long %>% 
  filter(original.value > 0,
         !is.na(original.value)) %>% 
  group_by(varname) %>% 
  mutate(cutoff_95 = as.numeric(quantile(original.value, 0.95, na.rm=T))) %>% 
  #Remove values that fall ABOVE the 95% cut-off.
  filter(original.value <= cutoff_95) %>% 
  #Find the natural breaks for each variable.
  mutate(naturalbreakpoints = list(getJenksBreaks(original.value, k = 4))) %>% 
  dplyr::select(varname, naturalbreakpoints) %>% 
  distinct() %>% 
  unnest_wider(col = naturalbreakpoints, ".") %>% 
  #Get rid of the highest bin break, we need to find the max value for each variable and add that instead.
  dplyr::select(-naturalbreakpoints.4,-naturalbreakpoints.1) %>% 
  left_join(data_long %>% 
              filter(original.value > 0,
              !is.na(original.value)) %>% 
              group_by(varname) %>% 
              summarise(naturalbreakpoints.4 = max(original.value)) %>% 
              distinct()
  ) %>% 
    left_join(data_long %>% 
              filter(original.value > 0,
              !is.na(original.value)) %>% 
              group_by(varname) %>% 
              summarise(naturalbreakpoints.1 = 0) %>% 
              distinct()
  ) %>% 
  dplyr::select(varname, naturalbreakpoints.1,naturalbreakpoints.2,
         naturalbreakpoints.3,naturalbreakpoints.4)

#Remove 0 values, bin with natural breaks.
data_bin = data_long %>% 
  filter(original.value > 0) %>% 
  #Bring in the natural breaks we calculated above.
  left_join(natural_break_points) %>% 
  #Set the group_by terms for the nesting.
  group_by(WATERSH,WATERBO,GNIS_NA,varname,original.value) %>% 
  nest() %>% 
  group_by(varname) %>% 
  #Bin the original value in 3 ways...
  mutate(bin_naturalbreak = as.numeric(cut(original.value, 
                                           breaks = unique(unlist(data)))))
```

```{r histograms}
number.hist.bins = 50

#Calculate for all rows which of the X histogram bins they are in.
data_bin = data_bin %>% 
  mutate(bin_hist = as.numeric(cut(original.value, breaks = number.hist.bins)))

#Natural breaks
naturalbreaksfig = ggplot() + 
  facet_wrap(~varname, scales = "free", ncol = 2) + 
  theme_classic() +
  geom_histogram(data = data_bin, aes(original.value), bins = number.hist.bins) +
  geom_vline(data = natural_break_points %>% 
               pivot_longer(-varname),
             aes(xintercept = value, 
             col = "darkblue", linetype = "dashed")) + 
  labs(x = "Variable Values", y = "Number of Waterbodies") +
  ggtitle("Natural Breaks")

naturalbreaksfig
```

```{r select_binning}
risk_data = waterb %>% 
  dplyr::select(WATERSH,WATERBO,GNIS_NA) %>% 
  left_join(data_bin %>% 
            dplyr::select(WATERSH,WATERBO,
                          GNIS_NA,varname,bin_naturalbreak) %>% 
            pivot_wider(names_from = varname, 
                        values_from = bin_naturalbreak)
            ) %>% 
  #Correct Transport Canada data to be -'ve.
  mutate(OperRes = replace(OperRes, OperRes == 1, -1))
```

```{r set_up_colour_palette}
# #Set up colour palette.
# g = scales::brewer_pal(type="seq", palette="Spectral",direction=-1)
# 
# #Get colour scale, based on Spectral palette, for 7 levels.
# my.colours_3 = g(4)
# my.colours_6 = g(7)

#Change first value (for "Unknown") to grey.
# my.colours_3 = c("#EBE6E6","#45DE31","#F79431","#F52528")
# my.colours_4 = c("#EBE6E6","#FFFF66","#45DE31","#F79431","#F52528")
# my.colours_6 = c("#EBE6E6","#4CD640","#D8F549","#FFFF66",
#                  "#FFD04D","#FF7038","#FA122D")
# 
# test = data.frame(a = c("Unknown","-2","-1","0","1","2",
#                            "3")) %>%
#  mutate(a = forcats::fct_inorder(as.factor(a)))
# 
# ggplot(test) +
#  geom_bar(aes(a, fill = a)) +
#  scale_fill_manual(values = my.colours_6)
my.colours = c("#f3ed8e","#eb9e4e","#F00320")
```

# Waterbody Risk Estimation - Use Variables

These variables include the number of total inspections, the sum of days fished, and the number of marinas in a given water body. 

Note that the histogram figures do not display data points where the value was 0; however, a large number of such data points exist in the dataset.

Combining Total inspections, number of marinas and sum of days fished as per the risk model, risk categories 1, 2 and 3 have the following number of waterbodies:

### Total Inspections

```{r use_vars_TtlInsp_without_popdensity} 
# Use Vars (without Population Density)

Usevars = c("TtlInsp","Marinas",
            # "PopDensity",
            "Sum.of.days.fished")

#Which waterbodies ONLY have population density info? 
just_popdens_records = risk_data %>% 
  st_drop_geometry() %>% 
  filter(is.na(TtlInsp),
         is.na(Sum.of.days.fished),
         is.na(Marinas),
         is.na(HR_mot),
         is.na(OperRes),
         is.na(NmbrMsF)) %>% 
  summarise(uniqID = paste0(WATERSH,WATERBO,GNIS_NA))

risk_data_use = risk_data %>% 
  dplyr::select(WATERSH,WATERBO,GNIS_NA,Usevars) %>% 
  st_drop_geometry() %>% 
  pivot_longer(cols = all_of(c(Usevars))) %>% 
  #Get rid of empty rows and 0s.
  filter(!is.na(value),
         value > 0) %>% 
  #Find out which waterbodies ONLY have data for population density - remove those.
  #filter(!paste0(WATERSH,WATERBO,GNIS_NA) %in% just_popdens_records$uniqID) %>% 
  #Add a column that groups rows by their variable of focus.
  mutate(Grouper = case_when(
    name %in% Usevars ~ "Use")) %>% 
  group_by(WATERSH,WATERBO,GNIS_NA,Grouper) %>% 
  #Calculate the mean value for each of the 3 groups of variables.
  mutate(MeanValue = mean(value)) %>% 
  #Get rid of the original variables, keeping the mean values.
  dplyr::select(-name,-value) %>% 
  distinct() %>% 
  #Pivot wider again, splitting the three averages into 3 columns.
  pivot_wider(names_from = Grouper, values_from = MeanValue) %>% 
  #Replace NA in the 3 variable group columns with 0s
  mutate(Use = replace_na(Use, 0)) %>% 
  #Calculate risk column.
  mutate(Risk = Use) %>% 
  #Bin the risk values.
  mutate(Risk = round(Risk,2))

waterb_risk = waterb %>% 
  dplyr::select(WATERSH,WATERBO,GNIS_NA) %>% 
  left_join(risk_data_use) %>% 
  mutate(Risk = as.character(Risk)) %>% 
  #Replace NA's with a factor called "Unknown"
  mutate(Risk = replace_na(Risk, "Unknown"))

#Mean, median
waterb %>% 
  dplyr::select(all_of(Usevars)) %>% 
  st_drop_geometry() %>% 
  pivot_longer(cols = everything()) %>% 
  rename(Variable = name) %>% 
  filter(!is.na(value),
         value > 0) %>% 
  group_by(Variable) %>% 
  summarise(mean = round(mean(value),1),
            median = median(value))

ggplot() +
  geom_sf(data = bc, fill = "lightgrey") +
  # geom_sf(data = waterb_risk %>% filter(Risk == "Unknown"),
  #         fill = "#EBE6E6", col = "#EBE6E6") +
  geom_sf(data = waterb_risk %>% filter(Risk != "Unknown"), 
           aes(fill = Risk, col = Risk)) +
  # geom_sf_label_repel(data = waterb_risk %>% 
  #                       filter(as.numeric(Risk) > 2.5),
  #                     aes(label = GNIS_NA),
  #                     force = 100) +
  scale_fill_brewer(palette = "RdYlGn", direction = -1) +
  scale_colour_brewer(palette = "RdYlGn", direction = -1) +
  ggthemes::theme_map() + 
  ggtitle("Use Variables") +
  theme(
    title = element_text(size = 16)
  )
```

# Waterbody Risk Estimation - High Risk Variables

These variables include the number of high-risk inspections and Transport Canada's operational restrictions.

### High-risk (Motorized) Inspections

The following water bodies have only non-motorized inspections (both high-risk and total inspections). The risk estimate of these water bodies was reduced by 1.

```{r 2nd_fig_high_risk_motorized}
#Note, we are also going to bump the risk_bin down 1 for any records that are
#non-motorized ONLY, with no transport canada data.
just_nonmot = waterb %>%
  filter(HR_nonmot > 0,
         HR_Cm_C == 0,
         HR_V_C_ == 0,
         HR_Sm_C == 0,
         Lowrisk_nonmot > 0,
         LwR_C_C == 0,
         LR_V_C_ == 0,
         LwR_S_C == 0) %>%
  filter(is.na(OperRes) | OperRes == "All Vessels Prohibited") %>% 
  mutate(uniqID = paste0(WATERSH,WATERBO,GNIS_NA))

data.frame(Just_nonMotorized = paste0(just_nonmot$GNIS_NA, collapse = ", "))

print("This list has been saved to the file 'Nonmotorized Inspections only Waterbodies list'.")

openxlsx::write.xlsx(just_nonmot %>% st_drop_geometry(),
                     paste0(my_opts$base_dir,"03_PrioritizationModel/output/Nonmotorized Inspections only Waterbodies list.xlsx"),
                     overwrite = T)

risk_data_highrisk = risk_data %>% 
  dplyr::select(WATERSH,WATERBO,GNIS_NA,all_of(Highriskvars)) %>% 
  st_drop_geometry() %>% 
  pivot_longer(cols = all_of(Highriskvars)) %>% 
  #Get rid of empty rows and 0s.
  filter(!is.na(value)) %>% 
  #Add a column that groups rows by their variable of focus.
  mutate(Grouper = case_when(
    name %in% Highriskvars ~ "Highrisk")) %>% 
  group_by(WATERSH,WATERBO,GNIS_NA,Grouper) %>% 
  #Calculate the mean value for each of the 3 groups of variables.
  mutate(MeanValue = mean(value)) %>% 
  #Get rid of the original variables, keeping the mean values.
  dplyr::select(-name,-value) %>% 
  distinct() %>% 
  #Pivot wider again, splitting the three averages into 3 columns.
  pivot_wider(names_from = Grouper, values_from = MeanValue) %>% 
  #Replace NA in the 3 variable group columns with 0s
  mutate(Highrisk = replace_na(Highrisk, 0)) %>% 
  #Calculate risk column.
  mutate(Risk = Highrisk) %>% 
  #Remove any rows that only have Operation Restriction data and no high-risk inspections.
  filter(Risk > -1) %>% 
  #Reduce risk bin by 1 for any records that match the "just_nonmot" subset
  mutate(Risk = case_when(
    paste0(WATERSH,WATERBO,GNIS_NA) %in% all_of(just_nonmot$uniqID) ~ Risk - 1,
    T ~ Risk)) %>% 
  #Bin the risk values.
  mutate(Risk = round(Risk,2))

waterb_risk = waterb %>% 
  dplyr::select(WATERSH,WATERBO,GNIS_NA) %>% 
  left_join(risk_data_highrisk) %>% 
  mutate(Risk = as.character(Risk)) %>% 
  #Replace NA's with a factor called "Unknown"
  mutate(Risk = replace_na(Risk, "Unknown"))

#Mean, median
waterb %>% 
  dplyr::select(HR_mot) %>% 
  st_drop_geometry() %>% 
  pivot_longer(cols = everything()) %>% 
  rename(Variable = name) %>% 
  filter(!is.na(value),
         value > 0) %>% 
  group_by(Variable) %>% 
  summarise(mean = round(mean(value),1),
            median = median(value))

#Number of lakes/rivers in each category of high-risk motorized inspections?
risk_data %>% 
  filter(!is.na(HR_mot)) %>% 
  st_drop_geometry() %>% 
  group_by(HR_mot) %>% 
  summarise(Lakes_in_bin = n()) %>% 
  rename(HighRisk_motorized = HR_mot)
  
ggplot() +
  geom_sf(data = bc, fill = "lightgrey") +
  # geom_sf(data = waterb_risk %>% filter(Risk == "Unknown"),
  #         fill = "#EBE6E6", col = "#EBE6E6") +
  geom_sf(data = waterb_risk %>% filter(Risk != "Unknown"), 
          aes(fill = Risk, col = Risk)) +
  # geom_sf_label_repel(data = waterb_risk %>% 
  #                       filter(as.numeric(Risk) > 2),
  #                     aes(label = GNIS_NA),
  #                     force = 100) +
  scale_fill_brewer(palette = "RdYlGn", direction = -1) +
  scale_colour_brewer(palette = "RdYlGn", direction = -1) +
  ggthemes::theme_map() + 
  ggtitle("High-Risk Inspections (motorized)",
          subtitle = "WBs with only non-motorized had risk reduced by 1") +
  theme(
    title = element_text(size = 16)
  )
```


# Mussel-fouled Inspections

```{r mussel_fouled}
#Massage data for high-risk inspections.
risk_data_mf = risk_data %>% 
  st_drop_geometry() %>% 
  #Get rid of empty rows.
  filter(!is.na(NmbrMsF)) %>% 
  #Calculate risk column.
  mutate(Risk = NmbrMsF) %>% 
  #Round the risk values to nearest whole number.
  mutate(Risk = round(Risk,2)) %>% 
  mutate(Risk = as.character(Risk)) %>% 
  mutate(Risk = replace_na(Risk, "Unknown"))

waterb_risk = waterb %>% 
  dplyr::select(WATERSH,WATERBO,GNIS_NA) %>% 
  left_join(risk_data_mf) %>% 
  #Replace NA's with a factor called "Unknown"
  mutate(Risk = replace_na(Risk, "Unknown"))

#Table of high-risk inspections

waterb %>% 
  dplyr::select(NmbrMsF) %>% 
  st_drop_geometry() %>% 
  pivot_longer(cols = everything()) %>% 
  rename(Variable = name) %>% 
  filter(!is.na(value),
         value > 0) %>% 
  group_by(Variable) %>% 
  summarise(mean = round(mean(value),1),
            median = median(value))

ggplot() +
  geom_sf(data = bc, fill = "lightgrey") +
  # geom_sf(data = waterb_risk %>% filter(Risk == "Unknown"),
  #         fill = "#EBE6E6", col = "#EBE6E6") +
  geom_sf(data = waterb_risk %>% filter(Risk != "Unknown"), 
          fill = "#fa3232", col = "#fa3232") +
  # geom_sf_label_repel(data = waterb_risk %>% 
  #                       filter(Risk != "Unknown"),
  #                     aes(label = GNIS_NA),
  #                         fill = "#fa3232",
  #                     force = 100) +
  ggthemes::theme_map() + 
  ggtitle("Mussel-fouled Inspections") +
  theme(
    title = element_text(size = 16)
  )
```


# Calcium at Subwatershed Scale

Note that the original binning of calcium was 1, 2 and 3 (<8 mg/L calcium, between 8 and 20 mg/L calcium, and 20+ mg/L of calcium); here, to diminish the weighting a bit of calcium, I roll these numbers back by 1, so that what was bin 1 becomes 0, what was bin 2 becomes 1, etc. Also note that there were many subwatersheds with insufficient data to find a mean calcium level. For those, I also assign them a risk category of 0, but I note that this is due to insufficient data in the 'calcium_data' column.

```{r calcium_subwatershed_figure}
calc = read_sf(paste0(my_opts$base_dir,'01_DataCleaning/output/ZQM_RiskAssessment_ssp370_10C_threshold_Subwatershed.gpkg'))

calc = calc %>% 
  mutate(Zebra_Risk = case_when(
    Zebra_Risk == "Minimal (less than 8 mg/L)" ~ "1 (Minimal - less than 8 mg/L)",
    Zebra_Risk == "Moderate (between 8 and 20 mg/L)" ~ "2 (Moderate - between 8 and 20 mg/L)",
    Zebra_Risk == "High (greater than 20 mg/L)" ~ "3 (High - greater than 20 mg/L)"
  ))

calc = calc %>% 
  mutate(Zebra_Risk = factor(Zebra_Risk, levels = c("1 (Minimal - less than 8 mg/L)",
                                              "2 (Moderate - between 8 and 20 mg/L)",
                                              "3 (High - greater than 20 mg/L)")))

waterbodies = read_sf(paste0(my_opts$remote_spatial_data,'shared_data_sets/WatershedGroups_lowres.shp'))

#Attach the ID name and number of each subwatershed to the calc data.
calc = calc %>% 
  left_join(waterbodies %>% 
              st_drop_geometry() %>% 
              rename(WatershedName = WATERSHE_1,
                     Watershed = WATERSHED_) %>% 
              dplyr::select(WatershedName, Watershed))

waterbodies = waterbodies %>% 
  filter(!WATERSHE_1 %in% calc$WatershedName)

ggplot() + 
  geom_sf(data = waterbodies, fill = "lightgrey") +
  geom_sf(data = calc, aes(fill = Zebra_Risk)) + 
  labs(fill = "Risk from Calcium Levels") +
  ggthemes::theme_map() + 
  scale_fill_manual(values = my.colours)
```

# Overall Risk Estimate

Using the model equation, we calculate an estimated risk factor for each waterbody for which we have at least one variable with data.

```{r overall_risk_estimate} 
#Combine the three risk data summaries from above...
risk_data_means = risk_data_use %>% 
  dplyr::select(-Risk) %>% 
  full_join(risk_data_highrisk %>% 
              dplyr::select(-Risk)) %>% 
  full_join(risk_data_mf %>% 
              dplyr::select(WATERSH,WATERBO,GNIS_NA,Risk) %>% 
              mutate(Risk = as.numeric(Risk)) %>% 
              rename(MusselFouled = Risk)) %>% 
  #Replace NA in the 3 variable group columns with 0s
  mutate(MusselFouled = replace_na(MusselFouled, 0),
         Use = replace_na(Use, 0),
         Highrisk = replace_na(Highrisk, 0)) %>% 
#Mussel-fouled will be reclassified as 1 or 0 (true or false)
  mutate(MusselFouled = replace(MusselFouled, MusselFouled > 0, 1)) %>% 
  rename(Watershed = WATERSH) %>% 
  #Add calcium to the waterbodies for which we have at least one other variable.
  left_join(calc %>% 
              st_drop_geometry() %>% 
              mutate(bin_bumped = as.character(bin_bumped)) %>% 
              mutate(bin_bumped = case_when(
                bin_bumped == "1" ~ "0",
                bin_bumped == "2" ~ "1",
                bin_bumped == "3" ~ "2",
                T ~ bin_bumped
              )) %>% 
              mutate(calcium_data = "Data present") %>% 
              rename(calcium_bin = bin_bumped) %>% 
              mutate(calcium_bin = as.numeric(calcium_bin)) %>% 
              dplyr::select(Watershed,calcium_bin,calcium_data)) %>% 
  #For lakes missing calcium data, correct the 'calcium_data' field.
  mutate(calcium_data = replace(calcium_data, is.na(calcium_data), "Missing")) %>% 
  #Replace missing values for calc with 0.
  mutate(calcium_bin = replace_na(calcium_bin, 0)) %>% 
  #Calculate risk column.
  mutate(Risk = Use + MusselFouled + Highrisk + calcium_bin) %>% 
  #Round the risk values.
  mutate(Risk = round(Risk,2)) %>% 
  distinct() %>% 
  rename(WATERSH = Watershed)

waterb_risk = waterb %>% 
  dplyr::select(WATERSH,WATERBO,GNIS_NA) %>% 
  left_join(risk_data_means) %>% 
  mutate(Risk = as.character(Risk)) %>% 
  #Replace NA's with a factor called "Unknown"
  mutate(Risk = replace_na(Risk, "Unknown"))

#Bin the final risk estimate into 3 bins.
waterb_risk = waterb_risk %>% 
  mutate(Risk_bin = as.numeric(Risk)) %>% 
  mutate(Risk_bin = as.numeric(cut(Risk_bin, 3)))
```

```{r histogram, fig.width=6,fig.height=6}
waterb_risk %>% 
  st_drop_geometry() %>% 
  filter(!is.na(Risk_bin)) %>% 
  group_by(Risk_bin) %>% 
  summarise(number_wbs_log = log(n())) %>%
  mutate(Risk_bin = as.character(Risk_bin)) %>% 
  ggplot() + 
  geom_col(aes(x=Risk_bin, y=number_wbs_log, fill = Risk_bin, col = Risk_bin)) + 
  theme_classic() +
  scale_fill_brewer(palette = "YlOrRd") +
  scale_colour_brewer(palette = "YlOrRd") +
  labs(y = "Log of Number of Waterbodies") +
  ggtitle("Histogram of Risk Estimates for BC Waterbodies",
          subtitle = "Majority are Low-Risk") + 
  theme(title = element_text(size = 13))
```

```{r bc_final_map}
#Map of province - Discrete Colour Scale
ggplot() +
  geom_sf(data = bc, fill = "lightgrey") +
  geom_sf(data = waterb_risk %>%
            filter(!is.na(Risk_bin)) %>% 
            mutate(Risk_bin = as.character(Risk_bin)), 
          aes(fill = Risk_bin, col = Risk_bin)) +
  # geom_sf_label_repel(data = waterb_risk %>% 
  #                             filter(Risk_bin == 3),
  #                     aes(label = GNIS_NA),
  #                     force = 100) +
  scale_fill_brewer(palette = "YlOrRd") +
  scale_colour_brewer(palette = "YlOrRd") +
  labs(fill = "Binned Risk Est.",col = "Binned Risk Est.") +
  ggthemes::theme_map() + 
  ggtitle("Risk Estimate of ZQ Mussel Invasion",
          subtitle = paste0("Total Waterbodies with Risk Estimate: ",nrow(waterb_risk %>% filter(!is.na(Risk_bin))))) +
  theme(
    title = element_text(size = 16)
  )

#And write these guys out to disk.
write_sf(waterb_risk %>% filter(Risk != "Unknown"),
         paste0(my_opts$remote_spatial_data,"Projects/ZQMussels/",my_opts$year," IMDP Final Report/data/spatial/waterbodies_zqm_ALL_risk_estimates.shp"))

```

Note: Up until this point, we have long water bodies like major rivers split into different polygons. This is inherited from the BCG Warehouse layers. I assume these rivers are split based on region/subwatershed. At this point in the analysis, we would like to narrow down our list. I am going to select the data for the highest risk section of each multi-polygon water body (i.e. river), assign those data to all of such a waterbody's sections, and then merge the polygons. This is the most conservative way to go about merging the polygons.

```{r get_lake_sampling_data}
#Get rid of waterbodies for which we have no risk estimate.
waterb_risk = waterb_risk %>% 
  filter(Risk != "Unknown")
#1902 WBs with risk estimates.

#Join the OG values for our risk variables to this layer with binned values.
waterb_og_values_and_bins = waterb_risk %>% 
  left_join(waterb_og_values_and_bins %>% 
              st_drop_geometry())

#Write out to W: drive.
write_sf(waterb_og_values_and_bins,
         paste0(my_opts$remote_spatial_data,"Projects/ZQMussels/",my_opts$year," IMDP Final Report/data/spatial/Waterbodies_with_binned_and_original_values.shp"))

#Find the river polygons that actually belong to the same water bodies. n = 39.
duplicated_river_names = waterb_risk %>% 
                      filter(str_detect(GNIS_NA, "River"),
                             GNIS_NA != "Elk River") %>% 
                      filter(duplicated(GNIS_NA)) %>% 
                      st_drop_geometry() %>% 
                      dplyr::select(GNIS_NA)

duplicated_rivers = waterb_risk %>% 
  filter(GNIS_NA %in% all_of(duplicated_river_names$GNIS_NA)) %>% 
  dplyr::select(WATERSH,WATERBO,GNIS_NA)

waterb_risk_rivers_to_merge = waterb_risk %>% 
  filter(paste0(WATERSH,WATERBO,GNIS_NA) %in% 
           all_of(paste0(duplicated_rivers$WATERSH,
                         duplicated_rivers$WATERBO,
                         duplicated_rivers$GNIS_NA)))
  
waterb_risk_rivers_merged = waterb_risk_rivers_to_merge %>% 
  group_by(GNIS_NA) %>% 
  #Arrange the dataframe so that the highest risk section of each river comes first.
  arrange(GNIS_NA,desc(as.numeric(Risk))) %>% 
  #Take the first value for each of our variables and set it as the default for each river (basically, homogenize the data in a conservative way), then merge polygons.
  summarise(across(!starts_with("geo"), first))
rm(waterb_risk_rivers_to_merge)

#Reattach rivers to the overall waterb_risk spatial object.
waterb_risk = waterb_risk %>% 
  filter(!paste0(WATERSH,WATERBO,GNIS_NA) %in% 
           all_of(paste0(duplicated_rivers$WATERSH,
                         duplicated_rivers$WATERBO,
                         duplicated_rivers$GNIS_NA))) %>% 
  #Add in the rivers.
  bind_rows(waterb_risk_rivers_merged)
  
#Add in which FLNRO region is each waterbody located!
flnro = read_sf(paste0(my_opts$remote_spatial_data,"shared_data_sets/FLNRO_Fishing_Boundaries.shp"))

waterb_risk_with_region = waterb_risk %>% 
  st_join(flnro %>% dplyr::select(REGION_G,REGION_N),
          join = st_intersects)

waterb_risk_with_region = waterb_risk_with_region %>% 
#Some waterbodies fall on the border between 2+ FLNRO regions...
  group_by(WATERSH,WATERBO,GNIS_NA) %>% 
  #For each unique grouping of watershed, waterbody id and name...
  mutate(REGION_G = paste0(REGION_G, collapse = ", "),
         REGION_N = paste0(REGION_N, collapse = ", ")) %>% 
  distinct() %>% 
  ungroup()

waterb_risk = waterb_risk_with_region

# Read in past years' sampling protocols that list which waterbodies were to be sampled.

#2021 waterbodies to be sampled.
sample_protocol_2021 = read_excel(paste0(my_opts$zqm_operations_data_folder,"Lake Monitoring/2021/Updates to protocol_waterbody ranking/2021 priority waterbodies for sampling.xlsx"),sheet = "2021 FINAL LIST")

#2022 waterbodies to be sampled.
sample_protocol_2022 = read_excel(paste0(my_opts$zqm_operations_data_folder,"Lake Monitoring/2022/Prioritization model/Final waterbody list with frequency added.xlsx"))

past_sample_protocols = sample_protocol_2021 %>% 
  mutate(sampling_year = 2021) %>% 
  bind_rows(sample_protocol_2022 %>% mutate(sampling_year = 2022))

#We have some waterbodies with various sampling stations proposed. We just need 1 row per wb.
sample_protocol = past_sample_protocols %>%
  group_by(Waterbody,sampling_year) %>%
  slice(1)

#Some names are spelled differently between this excel sheet and the BCG Warehouse waterbody layers. Fix these manually.
sample_protocol = sample_protocol %>%
  mutate(Waterbody = case_when(
    Waterbody == "Atlin lake" ~ "Atlin Lake",
    Waterbody == "Columbia River (Lower)" ~ "Columbia River",
    Waterbody == "Kinaskan" ~ "Kinaskan Lake",
    Waterbody == "Koocanusa Lake" ~ "Lake Koocanusa",
    Waterbody == "Marquart & Lunbom Lakes" ~ "Marquart Lake",
    T ~ Waterbody
  )) %>%
  group_by(Waterbody,sampling_year) %>%
  slice(1)

#Do a name match between "waterb_risk" and the protocol list
waterb_risk = waterb_risk %>%
  #Name join
  left_join(sample_protocol %>%
              filter(sampling_year == 2021) %>% 
              ungroup() %>% 
              dplyr::select(Waterbody) %>%
              rename(GNIS_NA = Waterbody) %>%
              mutate(prot_list_name_join_2021 = T)) %>%
  left_join(sample_protocol %>%
              filter(sampling_year == 2022) %>% 
              ungroup() %>% 
              dplyr::select(Waterbody) %>%
              rename(GNIS_NA = Waterbody) %>%
              mutate(prot_list_name_join_2022 = T)) %>% 
  mutate(prot_list_name_join_2021 = replace_na(prot_list_name_join_2021, F)) %>%
  mutate(prot_list_name_join_2022 = replace_na(prot_list_name_join_2022, F)) %>%
  #For each name match with more than 1 match, just keep the highest risk WB.
  group_by(GNIS_NA) %>%
  arrange(desc(Risk)) %>%
  mutate(name_risk_ranking = row_number()) %>%
  mutate(prot_list_name_join_2021 = case_when(
    prot_list_name_join_2021 == T & name_risk_ranking == 1 ~ T,
    prot_list_name_join_2021 == T & name_risk_ranking > 1 ~ F,
    prot_list_name_join_2021 == F ~ F
  )) %>% 
  mutate(prot_list_name_join_2022 = case_when(
    prot_list_name_join_2022 == T & name_risk_ranking == 1 ~ T,
    prot_list_name_join_2022 == T & name_risk_ranking > 1 ~ F,
    prot_list_name_join_2022 == F ~ F)) %>% 
  ungroup()

#And which lakes were actually sampled? Refer to the excel files that Martina sent to me (now formatted for CRB data submission)

# #2021 CRB lab results.
# crb_sample = read_excel(paste0(my_opts$zqm_operations_data_folder,"Lake Monitoring/",my.year,"/Lab Analysis/Final report/BC Veliger Sampling Inventory_CRB format_2021.xlsx"))
# 
# crb_sample = crb_sample %>%
#   rename(GNIS_NA = `Water Body Name`) %>%
#   dplyr::select(GNIS_NA) %>%
#   distinct() %>%
#   mutate(Sampled2021 = T) %>% 
#   filter(!is.na(GNIS_NA))

# waterb_risk = waterb_risk %>%
#   dplyr::left_join(crb_sample) %>%
#   #Just keep the biggest lake as the sampled lake for any given name.
#   mutate(Sampled2021 = case_when(
#     name_risk_ranking == 1 & Sampled2021 == T ~ T,
#     name_risk_ranking > 1 ~ F,
#     T ~ F
#   ))

#2022 Lake monitoring lab results.
lakes_monitored = read_excel(paste0(my_opts$zqm_operations_data_folder,"Lake Monitoring/",my.year,"/Lab Analysis/Final report and data/BC Veliger Sampling Inventory 2022_FinalReport.xlsx"))

#Just keep 1 row per water body name.
lakes_monitored = lakes_monitored %>%
  rename(GNIS_NA = Waterbody) %>%
  dplyr::select(GNIS_NA) %>%
  distinct() %>%
  mutate(!!sym(paste0("Sampled",my.year)) := T) %>% 
  filter(!is.na(GNIS_NA))

waterb_risk = waterb_risk %>%
  dplyr::left_join(lakes_monitored) %>%
  #Just keep the biggest lake as the sampled lake for any given name.
  mutate(!!sym(paste0("Sampled",my.year)) := case_when(
    name_risk_ranking == 1 & !!sym(paste0("Sampled",my.year)) == T ~ T,
    name_risk_ranking > 1 ~ F,
    T ~ F
  ))
```

```{r add_list_of_wbs_to_exclude}
wbs_to_exclude = read_excel(paste0(my_opts$zqm_operations_data_folder,"Lake Monitoring/waterbodies previously removed from list.xlsx")) %>%
  mutate(Waterbody = case_when(
    Waterbody == "Haha Lake (Stoney Lake)" ~ "Haha Lake",
    Waterbody == "Kitwancool" ~ "Kitwancool Lake",
    Waterbody == "Lillian lake" ~ "Lillian Lake",
    Waterbody == "North Barrier Lake" ~ "Barrier Lake",
    Waterbody == "Swalwell Lake (AKA Beaver Lake)" ~ "Beaver Lake",
    T ~ Waterbody
  )) %>%
  dplyr::select(Waterbody) %>%
  distinct() %>%
  mutate(WB_to_exclude = T) %>%
  rename(GNIS_NA = Waterbody)

# wbs_to_exclude %>%
#   filter(!GNIS_NA %in% all_of(waterb_risk$GNIS_NA))
#Just Downton Lake is missing from our ~2000 lakes with risk estimates.

#Join this list of waterbodies to exclude; for multiple name matches, just match
#the highest risk waterbody.
waterb_risk = waterb_risk %>%
  left_join(wbs_to_exclude) %>%
  mutate(WB_to_exclude = case_when(
    WB_to_exclude == T & name_risk_ranking == 1 ~ T,
    WB_to_exclude == T & name_risk_ranking > 1 ~ F,
    WB_to_exclude == F ~ F,
    is.na(WB_to_exclude) ~ F
  ))
```

```{r filtering_steps}
#Filtering steps outlined by Cass and Martina. First batch!
waterb_risk_complete = waterb_risk

waterb_risk = waterb_risk %>% 
  mutate(keep.me = case_when(
    Risk_bin == 3 ~ "keep",
    Risk_bin == 1 ~ "drop",
    Risk_bin == 2 & calcium_bin == 0 & calcium_data == "Data present" ~ "drop",
    T ~ "keep"
  )) %>% 
  filter(keep.me == "keep") %>% 
  dplyr::select(-keep.me)

#Second filtering step - need number of HR_mot and HR_nonmot.
#Make dataframe of waterbody name, WATERBO, and HR_mot, HR_nonmot.
HR_to_add = waterb %>% 
  st_drop_geometry() %>% 
  #Snag waterbodies that we have risk estimates for...
  filter(paste0(WATERSH,WATERBO,GNIS_NA) %in% 
           all_of(paste0(waterb_risk_with_region$WATERSH,
                         waterb_risk_with_region$WATERBO,
                         waterb_risk_with_region$GNIS_NA)),
         #Not including those duplicated rivers...
         !paste0(WATERSH,WATERBO,GNIS_NA) %in% 
           all_of(paste0(duplicated_rivers$WATERSH,
                         duplicated_rivers$WATERBO,
                         duplicated_rivers$GNIS_NA))) %>% 
  dplyr::select(WATERSH,WATERBO,GNIS_NA,
         HR_nonmot,HR_mot) %>% 
  #If we have polygons for lakes that were split in 2, we'll add the risk numbers.
  group_by(WATERBO,GNIS_NA) %>% 
  summarise(HR_nonmot = sum(HR_nonmot,na.rm=T),
            HR_mot = sum(HR_mot,na.rm=T))

HR_to_add_rivers = waterb %>% 
  st_drop_geometry() %>% 
  #Snag waterbodies that we have risk estimates for...
  filter(#Including those duplicated rivers...
         paste0(WATERSH,WATERBO,GNIS_NA) %in% 
           all_of(paste0(duplicated_rivers$WATERSH,
                         duplicated_rivers$WATERBO,
                         duplicated_rivers$GNIS_NA))) %>% 
    group_by(GNIS_NA) %>% 
    summarise(HR_nonmot2 = sum(HR_nonmot,na.rm=T),
            HR_mot2 = sum(HR_mot,na.rm=T))

waterb_risk = waterb_risk %>% 
  left_join(HR_to_add) %>% 
  left_join(HR_to_add_rivers) %>% 
  arrange(GNIS_NA) %>% 
  mutate(HR_nonmot = coalesce(HR_nonmot,HR_nonmot2),
         HR_mot = coalesce(HR_mot,HR_mot2)) %>% 
  dplyr::select(-HR_mot2,-HR_nonmot2)

#And now the actual second filtering step!
waterb_risk = waterb_risk %>% 
  filter(Use > 1.5) %>% 
  filter(HR_mot > 0 | Use > 2)

#Third filtering step: remove Kenai Creek and check for duplicated lakes.
waterb_risk = waterb_risk %>% 
  filter(GNIS_NA != "Kenai Creek")

#Just for Kinbasket Lake - merge the two rows, taking higher risk value data for most fields.
waterb_risk = waterb_risk %>% 
  filter(GNIS_NA != "Kinbasket Lake") %>% 
  bind_rows(
  waterb_risk %>% 
  filter(GNIS_NA == "Kinbasket Lake") %>% 
  group_by(GNIS_NA) %>% 
  arrange(GNIS_NA,desc(as.numeric(Risk))) %>% 
  summarise(across(!starts_with("geo"), first)) %>% 
  mutate(REGION_G = "4, 7O", REGION_N = "Kootenay, Omineca")
  )
```

```{r write_to_W_drive}
#Write to file
waterb_risk = waterb_risk %>%
           ungroup() %>%
           dplyr::select(-name_risk_ranking) %>%
           rename(OnProtocolList2021 = prot_list_name_join_2021,
                  OnProtocolList2022 = prot_list_name_join_2022) %>%
           mutate(Risk = as.numeric(Risk),
                  OnProtocolList2022 = as.character(OnProtocolList2022),
                  Sampled2022 = as.character(Sampled2022),
                  WB_to_exclude = as.character(WB_to_exclude))
write_sf(waterb_risk,
         paste0(my_opts$remote_spatial_data,"Projects/ZQMussels/",my_opts$year," IMDP Final Report/data/spatial/waterbodies_zqm_shortlist_risk_estimates.shp"))
```

```{r make_final_table}
waterbody_risk_table = st_centroid(waterb_risk) %>% 
  ungroup() %>% 
  st_transform(crs = 4326) %>% 
  mutate(Lat = st_coordinates(.)[,2],
         Long = st_coordinates(.)[,1]) %>%
  st_drop_geometry() %>% 
  # dplyr::select(-name_risk_ranking) %>% 
  # rename(OnProtocolList = prot_list_name_join) %>% 
  mutate(Risk = as.numeric(Risk)) %>% 
  arrange(desc(Risk))

#Replace the unique ID numbers of subwatersheds with their names.
waterbodies = read_sf(paste0(my_opts$remote_spatial_data,'shared_data_sets/WatershedGroups_lowres.shp')) %>% 
  st_drop_geometry() %>% 
  summarise(WATERSH = WATERSHED_, WatershedName = WATERSHE_1)

waterbody_risk_table = waterbody_risk_table %>% 
  left_join(waterbodies) %>% 
  dplyr::select(WatershedName, everything()) %>% 
  dplyr::select(-WATERSH)

#Rename the 1 waterbody with no name in the final tables.
waterbody_risk_table = waterbody_risk_table %>% 
  mutate(GNIS_NA = replace_na(GNIS_NA, "Unnamed Bull River WB"))
```

```{r show_top_100}
#Print out the first 100.
# waterbody_risk_table %>% 
#   slice(1:100)
```

```{r organize columns}
#Improve the order of the columns.
waterbody_risk_table = waterbody_risk_table %>% 
  dplyr::select(WatershedName:GNIS_NA,#OnProtocolList,Sampled2021,WB_to_exclude, 
                Use, Highrisk,HR_mot,HR_nonmot,
         MusselFouled:Long)
```


```{r write_excel_files_to_disk}
# ---------------- #
#      NOTE        #
# ---------------- #
# To run the code below (which generates an excel file wherein high-risk lakes that have not yet been sampled are highlighted in yellow), it will be necessary to first un-comment the section above to see which lakes were sampled in the previous year, as this section adds 2 columns to the waterbodies_risk table which are necessary for the code below to run successfully.

my.wb = createWorkbook("waterbodies_risk")

addWorksheet(wb = my.wb, sheetName = "Risk Estimates")

writeDataTable(wb = my.wb,
                    sheet = "Risk Estimates",
                    x = waterbody_risk_table,
                    withFilter = T)

#Highlight any high-risk waterbodies that have not been sampled.
posStyle <- createStyle(fontColour = "#fa3232", bgFill = "#ffff31")
conditionalFormatting(wb=my.wb, sheet='Risk Estimates', cols=which(names(waterbody_risk_table) == paste0('OnProtocolList',my_opts$year)),
                      rows=1:nrow(waterbody_risk_table), rule="== FALSE",
                      type = "expression",style = posStyle)
conditionalFormatting(wb=my.wb, sheet='Risk Estimates', cols=which(names(waterbody_risk_table) == paste0('Sampled',my_opts$year)),
                      rows=1:nrow(waterbody_risk_table), rule="== FALSE",
                      type = "expression",style = posStyle)

#Automatically adjust cell widths based on longest cell contents OR header.
width_vec <- apply(waterbody_risk_table, 2,
                   function(x) max(nchar(as.character(x)) + 2, na.rm = TRUE))
width_vec_header <- nchar(colnames(waterbody_risk_table)) + 2
max_vec_header <- pmax(width_vec, width_vec_header)
setColWidths(my.wb, "Risk Estimates",
             cols = 1:ncol(waterbody_risk_table), widths = max_vec_header)

#Write a second sheet for metadata.
addWorksheet(wb = my.wb,
             sheetName = "Metadata")
writeDataTable(wb = my.wb, sheet = "Metadata",
               x = data.frame(Variable = names(waterbody_risk_table),
                              Explanation = c("Name of waterbody's subwatershed according to BCG warehouse subwatershed layer",
                                              "Unique identifying number of waterbody polygon in BCG Warehouse lake, river or man-made waterbody layers",
                                              "Name of waterbody in BCG Warehouse lake, river or man-made waterbody layers",
                                              "Risk estimate for Use variables (total inspections, angler days, and number of marinas)",
                                              "Risk estimate for High-risk variables (High-risk inspections minus Transport Canada operation restrictions)",
                                              "The number of motorized high-risk inspections",
                                              "The number of non-motorized high-risk inspections",
                                              "Risk estimate (1 or 0) depending on mussel-fouled inspections or no",
                                              "Subwatershed-scale dissolved calcium levels (<8 is low risk, 8-20 medium risk, 20+ high risk); bins are 0, 1 and 2",
                                              "If calcium bin is 0, is this due to the calcium level being <8, or because that subwatershed lacked calcium data?",
                                              "Overall risk estimate calculated by combining the use, high-risk, mussel-fouled and calcium_bin risk estimates",
                                              "As last column, but binned into 3 bins",
                                              "FLRNO region code",
                                              "FLRNO region name",
                                              "Was the waterbody included in the 2021 list of priority lakes to sample?",
                                              "Was the waterbody included in the 2022 list of priority lakes to sample?",
                                              "Was the lake sampled in 2022?",
                                              "Waterbodies previously slated for exclusion from sampling",
                                              "Latitude of centroid of polygon",
                                              "Longitude of centroid of polygon")),
               withFilter = F)

setColWidths(my.wb, "Metadata",
             cols = 1, widths = 15)

# saveWorkbook(my.wb,
#              "output/waterbodies with risk estimates post filtering.xlsx",
#              overwrite = T)

saveWorkbook(my.wb,
             paste0(my_opts$zqm_operations_data_folder,"Lake Monitoring/",my_opts$year+1,"/Prioritization model/waterbodies with risk estimates post filtering_",my_opts$year+1,".xlsx"),
             overwrite = T)
```

```{r final_waterbody_list}

# Please see note in above chunk. It applies to this section as well, I'm fairly sure.

final_waterbody_list = waterbody_risk_table %>%
  ungroup() %>%
  summarise(Region = REGION_N,
            Waterbody = GNIS_NA,
            `Veliger Sampling Frequency` = "Undecided",
            Lat = round(Lat, 4),
            Long = round(Long, 4),
            Risk_bin = Risk_bin)

fwl_rivers = final_waterbody_list %>%
  filter(str_detect(Waterbody, "River"))

fwl_lakes = final_waterbody_list %>%
  filter(!str_detect(Waterbody, "River"))

#Change coords for rivers to NA (delete fields!)
fwl_rivers$Lat = NULL
fwl_rivers$Long = NULL

final_waterbody_list = fwl_lakes %>%
  arrange(Waterbody) %>%
  bind_rows(fwl_rivers %>% arrange(Waterbody)) %>%
  arrange()

openxlsx::write.xlsx(final_waterbody_list,
                     paste0(my_opts$zqm_operations_data_folder,"Lake Monitoring/",my_opts$year+1,"/Prioritization model/Final waterbody list based on risk estimates_",my_opts$year+1,".xlsx"),
                     overwrite = T)
```

```{r make_comparison_file}
# Load in year 1
year_1_final_list = read_excel(paste0(my_opts$zqm_operations_data_folder,'Lake Monitoring/2022/Prioritization model/Final waterbody list with frequency added.xlsx'))

year_1 = read_excel(paste0(my_opts$zqm_operations_data_folder,'Lake Monitoring/2022/Prioritization model/waterbodies with risk estimates post filtering.xlsx'))

year_1 = year_1 %>% 
  filter(GNIS_NA %in% year_1_final_list$Waterbody)

# Load in year 2
year_2 = read_excel(paste0(my_opts$zqm_operations_data_folder,"Lake Monitoring/2023/Prioritization model/waterbodies with risk estimates post filtering_2023.xlsx"))

# Compare!

# Old waterbodies in year 1 that are not in year 2.
waterbodies_dropped_from_year1 = year_1 %>% 
  mutate(my_key = paste0(GNIS_NA)) %>% 
  filter(!my_key %in% all_of(paste0(year_2$GNIS_NA)))

# New waterbodies in year 2
waterbodies_added_in_year2 = year_2 %>% 
  mutate(my_key = paste0(GNIS_NA)) %>% 
  filter(!my_key %in% paste0(year_1$GNIS_NA))

# Find out which values have changed for these new waterbodies in year 2.
all_data_previous_year = read_sf(paste0(my_opts$remote_spatial_data,'Projects/ZQMussels/',my_opts$year-1,' IMDP Final Report/data/spatial/waterbodies_zqm_ALL_risk_estimates.shp')) 

# Data from last year's sampling list for those lakes that were
# added to this year's sampling list. Has anything changed? 
table_differences = all_data_previous_year %>% 
  st_drop_geometry() %>% 
  dplyr::select(WATERBO:Risk_bn) %>% 
  rename(Risk_bin = Risk_bn,
         Highrisk = Highrsk,
         MusselFouled = MsslFld,
         calcium_bin = clcm_bn,
         calcium_data = clcm_dt) %>% 
  mutate(Risk = as.numeric(Risk)) %>% 
  filter(WATERBO %in% waterbodies_added_in_year2$WATERBO,
         GNIS_NA %in% waterbodies_added_in_year2$GNIS_NA) %>% 
  arrange(GNIS_NA) %>%
  diffdf::diffdf(waterbodies_added_in_year2 %>% 
            dplyr::select(WATERBO:Risk_bin) %>% 
            dplyr::select(-HR_mot,-HR_nonmot) %>% 
            arrange(GNIS_NA))

table_differences$VarDiff_calcium_bin$..ROWNUMBER..
table_differences$VarDiff_Risk$..ROWNUMBER..
table_differences$VarDiff_Risk_bin$..ROWNUMBER..

# Save results.
my.wb = createWorkbook("annual_sampling_lists_comparison")
addWorksheet(wb = my.wb, sheetName = "Only in older year")
addWorksheet(wb = my.wb, sheetName = "Only in recent year")

writeDataTable(wb = my.wb,
                    sheet = "Only in older year",
                    x = waterbodies_dropped_from_year1,
                    withFilter = T)
writeDataTable(wb = my.wb,
                    sheet = "Only in recent year",
                    x = waterbodies_added_in_year2 %>% arrange(GNIS_NA),
                    withFilter = T)
# Add red text for values that have changed from year 1 to year 2.
openxlsx::addStyle(wb = my.wb,
                   sheet = 'Only in recent year',
                   style = createStyle(fontColour = 'red'),
                   rows = c(table_differences$VarDiff_calcium_bin$..ROWNUMBER..+1),
                   cols = which(names(waterbodies_added_in_year2) == 'calcium_bin'))
openxlsx::addStyle(wb = my.wb,
                   sheet = 'Only in recent year',
                   style = createStyle(fontColour = 'red'),
                   rows = c(table_differences$VarDiff_Risk$..ROWNUMBER..+1),
                   cols = which(names(waterbodies_added_in_year2) == 'Risk'))
openxlsx::addStyle(wb = my.wb,
                   sheet = 'Only in recent year',
                   style = createStyle(fontColour = 'red'),
                   rows = c(table_differences$VarDiff_Risk_bin$..ROWNUMBER..+1),
                   cols = which(names(waterbodies_added_in_year2) == 'Risk_bin'))
saveWorkbook(my.wb,
             paste0(my_opts$zqm_operations_data_folder,"Lake Monitoring/",my_opts$year+1,"/Prioritization model/Sampling_list_comparison_",my_opts$year+1,"_with_",my_opts$year,".xlsx"),
             overwrite = T)
```


